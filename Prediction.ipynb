{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df = pd.read_csv(\"dataset_for_prediction.csv\")\n",
    "#salary_df[(salary_df[\"Year\"]==2000) & (salary_df[\"Tm\"]==\"SEA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = salary_df[[\"Tm\", \"Year\", \"Salaries\"]]\n",
    "teams = teams.groupby([\"Tm\", \"Year\"]).sum()\n",
    "teams.rename(columns={'Salaries':'Teamcap'}, inplace=True)\n",
    "dataset = pd.merge(left=salary_df, right=teams, left_on=[\"Tm\", \"Year\"], right_on=[\"Tm\", \"Year\"])\n",
    "dataset['Wage%'] = round(dataset['Salaries'] / dataset['Teamcap']*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  Year   Age     G      MP   PER    TS%   3PAr    FTr  ORB%  \\\n",
      "0               0  2000  24.0  82.0  3070.0  20.6  0.570  0.288  0.282   3.2   \n",
      "1               1  2000  23.0  27.0   361.0   4.3  0.310  0.147  0.042   1.6   \n",
      "2              18  2000  30.0  81.0  2899.0  21.1  0.551  0.077  0.380   2.8   \n",
      "3              61  2000  32.0  80.0  2129.0  12.7  0.550  0.004  0.563  12.8   \n",
      "4             108  2000  27.0  81.0  2909.0  17.8  0.534  0.162  0.194   4.3   \n",
      "5             124  2000  22.0  44.0   447.0  15.8  0.517  0.033  0.557  13.1   \n",
      "6             133  2000  31.0  68.0  1488.0  15.6  0.539  0.000  0.303  14.0   \n",
      "7               2  2000  29.0  82.0  2593.0  17.4  0.524  0.223  0.257   2.3   \n",
      "8              78  2000  25.0  61.0   879.0   7.2  0.451  0.478  0.235   4.1   \n",
      "9              98  2000  22.0  73.0  2583.0  19.8  0.550  0.255  0.409   3.5   \n",
      "10            101  2000  24.0  79.0  1797.0  13.8  0.527  0.002  0.260  11.0   \n",
      "11            126  2000  23.0  82.0  3003.0  17.8  0.494  0.189  0.295   7.2   \n",
      "12            131  2000  27.0  68.0  1378.0  11.8  0.531  0.187  0.438   4.3   \n",
      "13              3  2000  31.0  82.0  2590.0  19.5  0.542  0.360  0.221   2.7   \n",
      "14             41  2000  23.0  82.0  1479.0  11.9  0.532  0.337  0.190   3.2   \n",
      "15             47  2000  23.0   4.0    63.0  14.2  0.398  0.118  0.412   8.7   \n",
      "16             73  2000  20.0  77.0  1370.0  14.1  0.553  0.023  0.557   9.8   \n",
      "17            119  2000  31.0  20.0   148.0  12.0  0.499  0.083  0.292   8.1   \n",
      "18              4  2000  30.0  59.0  1173.0  10.2  0.481  0.011  0.389   6.2   \n",
      "19             46  2000  21.0  71.0  1373.0  11.6  0.482  0.127  0.220   3.1   \n",
      "20             54  2000  26.0  82.0  2909.0  12.3  0.496  0.006  0.248   5.2   \n",
      "21             86  2000  28.0  80.0  1831.0  14.1  0.555  0.393  0.210   3.9   \n",
      "22              5  2000  28.0  80.0  2726.0  14.6  0.609  0.564  0.222   2.0   \n",
      "23             34  2000  31.0  60.0   718.0   6.9  0.430  0.067  0.125   2.4   \n",
      "24              6  2000  19.0  24.0   130.0   7.6  0.397  0.171  0.343   3.6   \n",
      "25              7  2000  27.0  82.0  1691.0  16.5  0.569  0.166  0.339   1.1   \n",
      "26             27  2000  30.0  74.0  2127.0  17.4  0.537  0.000  0.337  14.0   \n",
      "27             35  2000  23.0  19.0    86.0  25.6  0.632  0.043  1.087  16.3   \n",
      "28             48  2000  19.0  50.0   854.0  10.8  0.524  0.129  0.420   6.4   \n",
      "29             81  2000  33.0  32.0   634.0  11.2  0.524  0.213  0.519   5.3   \n",
      "...           ...   ...   ...   ...     ...   ...    ...    ...    ...   ...   \n",
      "10191        9790  2019  25.0  56.0  1850.0  30.3  0.597  0.141  0.422   9.9   \n",
      "10192        9803  2019  22.0  64.0   896.0  17.5  0.644  0.015  0.247   8.8   \n",
      "10193        9848  2019  28.0  47.0   909.0  11.6  0.552  0.395  0.210   3.7   \n",
      "10194        9891  2019  24.0   6.0    38.0   3.1  0.349  0.833  0.167   5.5   \n",
      "10195        9904  2019  27.0  44.0   878.0   6.8  0.497  0.567  0.180   4.1   \n",
      "10196        9906  2019  28.0  67.0  2402.0  19.4  0.555  0.313  0.234   3.3   \n",
      "10197        9927  2019  20.0  61.0  1169.0   9.4  0.517  0.378  0.163   2.2   \n",
      "10198        9942  2019  22.0  18.0   247.0   8.9  0.496  0.374  0.143   3.8   \n",
      "10199        9947  2019  31.0  26.0   377.0   6.9  0.517  0.568  0.102   2.8   \n",
      "10200       10031  2019  28.0  69.0  1757.0   8.4  0.550  0.752  0.147   0.8   \n",
      "10201       10040  2019  29.0  53.0  1463.0  11.5  0.567  0.331  0.111   2.5   \n",
      "10202       10071  2019  23.0  59.0   935.0  17.9  0.603  0.014  0.246   9.2   \n",
      "10203       10091  2019  24.0  42.0  1250.0  14.0  0.502  0.255  0.180   4.1   \n",
      "10204       10107  2019  24.0  73.0  2232.0  21.0  0.600  0.179  0.447   7.6   \n",
      "10205       10152  2019  32.0   2.0    20.0   4.6  0.405  0.778  0.222  10.5   \n",
      "10206       10201  2019  24.0  46.0  1079.0   9.7  0.485  0.559  0.068   5.4   \n",
      "10207       10207  2019  23.0   8.0   189.0  23.4  0.613  0.228  0.446   7.2   \n",
      "10208        9774  2019  31.0  76.0  2143.0  16.7  0.574  0.294  0.288   1.9   \n",
      "10209        9833  2019  29.0  69.0  1402.0  11.5  0.483  0.327  0.242   2.7   \n",
      "10210        9905  2019  22.0  50.0   646.0  11.9  0.518  0.485  0.191   0.9   \n",
      "10211        9937  2019  22.0  14.0    64.0   6.3  0.333  0.125  0.500   7.1   \n",
      "10212        9955  2019  27.0  82.0  2063.0  11.0  0.474  0.312  0.078   2.1   \n",
      "10213       10017  2019  32.0  23.0   725.0   9.2  0.543  0.619  0.229   1.7   \n",
      "10214       10020  2019  27.0  77.0  1340.0  11.6  0.617  0.488  0.187   1.4   \n",
      "10215       10069  2019  28.0  45.0   371.0  16.8  0.537  0.088  0.154   8.9   \n",
      "10216       10073  2019  26.0  36.0  1147.0  17.6  0.519  0.367  0.240   2.1   \n",
      "10217       10108  2019  23.0  10.0    47.0   8.1  0.500  0.333  0.000   4.8   \n",
      "10218       10124  2019  22.0  74.0  1838.0  21.9  0.630  0.024  0.416  11.5   \n",
      "10219       10180  2019  22.0  74.0  2119.0  18.0  0.567  0.251  0.258   5.4   \n",
      "10220       10212  2019  30.0  81.0  2489.0  16.2  0.569  0.174  0.161   8.7   \n",
      "\n",
      "       ...  Tm_PHO  Tm_POR  Tm_SAC  Tm_SAS  Tm_SEA  Tm_TOR  Tm_TOT  Tm_UTA  \\\n",
      "0      ...       0       0       0       0       0       0       0       0   \n",
      "1      ...       0       0       0       0       0       0       0       0   \n",
      "2      ...       0       0       0       0       0       0       0       0   \n",
      "3      ...       0       0       0       0       0       0       0       0   \n",
      "4      ...       0       0       0       0       0       0       0       0   \n",
      "5      ...       0       0       0       0       0       0       0       0   \n",
      "6      ...       0       0       0       0       0       0       0       0   \n",
      "7      ...       0       0       0       0       0       0       0       0   \n",
      "8      ...       0       0       0       0       0       0       0       0   \n",
      "9      ...       0       0       0       0       0       0       0       0   \n",
      "10     ...       0       0       0       0       0       0       0       0   \n",
      "11     ...       0       0       0       0       0       0       0       0   \n",
      "12     ...       0       0       0       0       0       0       0       0   \n",
      "13     ...       0       0       0       0       0       0       0       0   \n",
      "14     ...       0       0       0       0       0       0       0       0   \n",
      "15     ...       0       0       0       0       0       0       0       0   \n",
      "16     ...       0       0       0       0       0       0       0       0   \n",
      "17     ...       0       0       0       0       0       0       0       0   \n",
      "18     ...       0       0       0       0       0       0       0       0   \n",
      "19     ...       0       0       0       0       0       0       0       0   \n",
      "20     ...       0       0       0       0       0       0       0       0   \n",
      "21     ...       0       0       0       0       0       0       0       0   \n",
      "22     ...       0       0       0       0       1       0       0       0   \n",
      "23     ...       0       0       0       0       1       0       0       0   \n",
      "24     ...       0       0       0       0       0       0       0       0   \n",
      "25     ...       0       0       0       0       0       0       0       0   \n",
      "26     ...       0       0       0       0       0       0       0       0   \n",
      "27     ...       0       0       0       0       0       0       0       0   \n",
      "28     ...       0       0       0       0       0       0       0       0   \n",
      "29     ...       0       0       0       0       0       0       0       0   \n",
      "...    ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "10191  ...       0       0       0       0       0       0       0       0   \n",
      "10192  ...       0       0       0       0       0       0       0       0   \n",
      "10193  ...       0       0       0       0       0       0       0       0   \n",
      "10194  ...       0       0       0       0       0       0       0       0   \n",
      "10195  ...       0       0       0       0       0       0       0       0   \n",
      "10196  ...       0       0       0       0       0       0       0       0   \n",
      "10197  ...       0       0       0       0       0       0       0       0   \n",
      "10198  ...       0       0       0       0       0       0       0       0   \n",
      "10199  ...       0       0       0       0       0       0       0       0   \n",
      "10200  ...       0       0       0       0       0       0       0       0   \n",
      "10201  ...       0       0       0       0       0       0       0       0   \n",
      "10202  ...       0       0       0       0       0       0       0       0   \n",
      "10203  ...       0       0       0       0       0       0       0       0   \n",
      "10204  ...       0       0       0       0       0       0       0       0   \n",
      "10205  ...       0       0       0       0       0       0       0       0   \n",
      "10206  ...       0       0       0       0       0       0       0       0   \n",
      "10207  ...       0       0       0       0       0       0       0       0   \n",
      "10208  ...       0       0       0       0       0       0       0       0   \n",
      "10209  ...       0       0       0       0       0       0       0       0   \n",
      "10210  ...       0       0       0       0       0       0       0       0   \n",
      "10211  ...       0       0       0       0       0       0       0       0   \n",
      "10212  ...       0       0       0       0       0       0       0       0   \n",
      "10213  ...       0       0       0       0       0       0       0       0   \n",
      "10214  ...       0       0       0       0       0       0       0       0   \n",
      "10215  ...       0       0       0       0       0       0       0       0   \n",
      "10216  ...       0       0       0       0       0       0       0       0   \n",
      "10217  ...       0       0       0       0       0       0       0       0   \n",
      "10218  ...       0       0       0       0       0       0       0       0   \n",
      "10219  ...       0       0       0       0       0       0       0       0   \n",
      "10220  ...       0       0       0       0       0       0       0       0   \n",
      "\n",
      "       Tm_VAN  Tm_WAS  \n",
      "0           0       0  \n",
      "1           0       0  \n",
      "2           0       0  \n",
      "3           0       0  \n",
      "4           0       0  \n",
      "5           0       0  \n",
      "6           0       0  \n",
      "7           0       0  \n",
      "8           0       0  \n",
      "9           0       0  \n",
      "10          0       0  \n",
      "11          0       0  \n",
      "12          0       0  \n",
      "13          0       0  \n",
      "14          0       0  \n",
      "15          0       0  \n",
      "16          0       0  \n",
      "17          0       0  \n",
      "18          0       1  \n",
      "19          0       1  \n",
      "20          0       1  \n",
      "21          0       1  \n",
      "22          0       0  \n",
      "23          0       0  \n",
      "24          0       0  \n",
      "25          0       0  \n",
      "26          0       0  \n",
      "27          0       0  \n",
      "28          0       0  \n",
      "29          0       0  \n",
      "...       ...     ...  \n",
      "10191       0       0  \n",
      "10192       0       0  \n",
      "10193       0       0  \n",
      "10194       0       0  \n",
      "10195       0       0  \n",
      "10196       0       0  \n",
      "10197       0       0  \n",
      "10198       0       0  \n",
      "10199       0       0  \n",
      "10200       0       0  \n",
      "10201       0       0  \n",
      "10202       0       0  \n",
      "10203       0       0  \n",
      "10204       0       0  \n",
      "10205       0       0  \n",
      "10206       0       0  \n",
      "10207       0       0  \n",
      "10208       0       0  \n",
      "10209       0       0  \n",
      "10210       0       0  \n",
      "10211       0       0  \n",
      "10212       0       0  \n",
      "10213       0       0  \n",
      "10214       0       0  \n",
      "10215       0       0  \n",
      "10216       0       0  \n",
      "10217       0       0  \n",
      "10218       0       0  \n",
      "10219       0       0  \n",
      "10220       0       0  \n",
      "\n",
      "[10221 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_dum = pd.get_dummies(columns=[\"Pos\", \"Tm\"], data=dataset)\n",
    "prediction_data = data_dum.drop(columns = [\"Player\"])\n",
    "print(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = prediction_data.copy().drop(columns=[\"Wage%\", \"Salaries\"])\n",
    "y = prediction_data[\"Wage%\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(X_train)\n",
    "standardized_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using Random Forest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fb59ace2aeac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# TODO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstandardized_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=4,random_state=0).fit(X_train, y_train)\n",
    "acc = accuracy_score(y_test, rf.predict(standardized_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rayAllen = data_dum[data_dum[\"Player\"] == \"Kobe Bryant\"]\n",
    "rayAllen = rayAllen.drop(columns=[\"Player\", \"Salaries\", \"Wage%\"])\n",
    "#rayAllen_pred = rf.predict(rayAllen)\n",
    "#print(rayAllen_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using Linear Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.21870918e+00 -2.91186115e+00  2.08421909e-01 -6.89421356e-01\n",
      " -1.45236812e+00  7.61939798e-01  7.12314262e-02  1.22424600e-01\n",
      "  8.71800359e-02  2.12192860e-01  7.10034023e-02 -2.76313441e-01\n",
      "  1.97702435e-01  3.08732563e-02  4.62322933e-03 -2.30628134e-03\n",
      " -3.55239190e-01 -1.61266918e+00 -1.51939209e+00  3.38434315e+00\n",
      " -5.96793592e-01  3.27942253e-01  1.96391387e-01 -7.35643291e-01\n",
      "  9.71450195e-01 -2.36238241e+11 -1.76045467e+11 -2.15977259e-01\n",
      "  1.33250883e+11  5.94798607e+10  1.93641084e-02  3.45339934e+11\n",
      "  1.41500619e+11  2.02189128e-01  8.23170490e-02  4.96520148e+10\n",
      "  1.66784164e+00 -2.49805369e-02 -4.61533198e+10 -1.08285523e+11\n",
      "  1.49270583e+11 -5.12870103e-01 -5.32679920e-01  1.68163834e-01\n",
      "  7.97789849e-01 -8.97544929e-02 -2.25322265e+11 -4.81743804e+00\n",
      " -1.15465349e+00  1.07075879e+11  1.08485792e+11  1.05819767e+11\n",
      "  1.01924894e+11  1.08871075e+11 -1.69671496e+10 -1.67157921e+10\n",
      " -1.08422726e+10 -1.18397746e+10 -5.20722313e+09 -1.50258297e+10\n",
      " -8.40608430e+09 -1.67157921e+10 -1.64968479e+10 -1.66431762e+10\n",
      " -1.60866138e+10 -1.60107429e+10 -1.63118308e+10 -1.51072739e+10\n",
      " -1.58192647e+10 -1.55467230e+10 -1.63861229e+10 -1.59726546e+10\n",
      " -1.68240440e+10 -1.63490249e+10 -1.33738146e+10 -1.06663988e+10\n",
      " -4.95378263e+09 -1.05474308e+10 -1.67880489e+10 -1.25077816e+10\n",
      " -1.55073486e+10 -1.52285304e+10 -1.57031126e+10 -1.52687105e+10\n",
      " -1.58192647e+10 -1.59726546e+10 -1.01817443e+10 -1.61243977e+10\n",
      " -2.81833179e+10 -1.56251377e+10 -4.40284026e+09 -1.61243977e+10]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(standardized_data, y_train)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.03635665e+14]\n",
      "2331    21.4\n",
      "Name: Wage%, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(rayAllen[rayAllen[\"Year\"] == 2005]))\n",
    "print(dataset[dataset[\"Player\"] == \"Kobe Bryant\"][\"Wage%\"][dataset[\"Year\"] == 2005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Key Players Salaries ###\n",
    "#### Predicting new contract salary by year ####\n",
    "Chosen players:\n",
    "* Anthony Davis\n",
    "* Damian Lillard\n",
    "* Giannis Antetokounmpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [\"Anthony Davis\", \"Damian Lillard\", \"Giannis Antetokounmpo\"]\n",
    "choosenModel = lr\n",
    "for player in players:\n",
    "    predictedSalary = choosenModel.predict(data_dum[(data_dum[\"Player\"] == player) & (salary_df[\"Year\"] == 2019 )].drop(columns=[\"Player\", \"Salaries\"]))\n",
    "    salaryNow = salary_df[(salary_df[\"Player\"] == player) & (salary_df[\"Year\"] == 2019 )][\"Salaries\"].iloc[0]\n",
    "    print(\"Player: \" + str(player)+\"; \"+ \"Current Salary: \"+ str(salaryNow) +\"; \"+\"Predicted next season salary: \"+ str(predictedSalary))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
